{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef0c8186",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30d76c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f678ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34bd2eab",
   "metadata": {},
   "source": [
    "## Análise Exploratória de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d391a364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49454</th>\n",
       "      <td>49456</td>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>Como a média de votos era muito baixa, e o fat...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49455</th>\n",
       "      <td>49457</td>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>O enredo teve algumas reviravoltas infelizes e...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49456</th>\n",
       "      <td>49458</td>\n",
       "      <td>I am amazed at how this movieand most others h...</td>\n",
       "      <td>Estou espantado com a forma como este filme e ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49457</th>\n",
       "      <td>49459</td>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>A Christmas Together realmente veio antes do m...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49458</th>\n",
       "      <td>49460</td>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>O drama romântico da classe trabalhadora do di...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49459 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            text_en  \\\n",
       "0          1  Once again Mr. Costner has dragged out a movie...   \n",
       "1          2  This is an example of why the majority of acti...   \n",
       "2          3  First of all I hate those moronic rappers, who...   \n",
       "3          4  Not even the Beatles could write songs everyon...   \n",
       "4          5  Brass pictures movies is not a fitting word fo...   \n",
       "...      ...                                                ...   \n",
       "49454  49456  Seeing as the vote average was pretty low, and...   \n",
       "49455  49457  The plot had some wretched, unbelievable twist...   \n",
       "49456  49458  I am amazed at how this movieand most others h...   \n",
       "49457  49459  A Christmas Together actually came before my t...   \n",
       "49458  49460  Working-class romantic drama from director Mar...   \n",
       "\n",
       "                                                 text_pt sentiment  \n",
       "0      Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n",
       "1      Este é um exemplo do motivo pelo qual a maiori...       neg  \n",
       "2      Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n",
       "3      Nem mesmo os Beatles puderam escrever músicas ...       neg  \n",
       "4      Filmes de fotos de latão não é uma palavra apr...       neg  \n",
       "...                                                  ...       ...  \n",
       "49454  Como a média de votos era muito baixa, e o fat...       pos  \n",
       "49455  O enredo teve algumas reviravoltas infelizes e...       pos  \n",
       "49456  Estou espantado com a forma como este filme e ...       pos  \n",
       "49457  A Christmas Together realmente veio antes do m...       pos  \n",
       "49458  O drama romântico da classe trabalhadora do di...       pos  \n",
       "\n",
       "[49459 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resenha = pd.read_csv(\"imdb-reviews-pt-br.csv\")\n",
    "resenha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5318ba9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            int64\n",
       "text_en      object\n",
       "text_pt      object\n",
       "sentiment    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando o tipo de dado, tenho string e float\n",
    "resenha.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c1d1d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataset possui 49459 linhas e 4 colunas\n"
     ]
    }
   ],
   "source": [
    "# Tamanho do dataset\n",
    "resenha.shape\n",
    "print('O dataset possui {} linhas e {} colunas'.format(resenha.shape[0], resenha.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91188132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "text_en      0\n",
       "text_pt      0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zero dados null na base \n",
    "resenha.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9b1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb068cca",
   "metadata": {},
   "source": [
    "## Separação dos dados para treino e teste com Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53a3d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separei os dados como treino e teste, no primeiro parametro eu passo (resenhas.text_pt) que são os dados que o algoritimo deve separar \n",
    "# e no segundo parametro resenhas.sentiment que são os dados que ele deve treinar, e por fim o random que é minha SEED.\n",
    "\n",
    "treino, teste, classe_treino, classe_teste = train_test_split(resenha.text_pt,\n",
    "                                                              resenha.sentiment,\n",
    "                                                              random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f912d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6801170b",
   "metadata": {},
   "source": [
    "## Aplicando o método de classificação "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a692948",
   "metadata": {},
   "source": [
    "#### Para construção desse modelo de machine learning eu vou usar o metodo de aprendizagem supervisionada com aplicação em classificacao \n",
    "#### Classificacao é uma tecnica para aprendizagem supervisionado, onde eu já rotulei os dados, então a maquina trabalha de acordo com essas entradas, esse algoritmo é usado para classificação binária, ou seja, é usado em problemas nos quais existem apenas duas classes. Ele traçar uma linha que divide o conjunto de dados em dois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab90b7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fdba215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeira etapa para esse processamento com ML é conhecer um pouco melhor os dados textuais,o algoritimo não interpreta dados string, apenas números \n",
    "# Então vou iniciar essa etapa conhecendo meus dados e analisando as criticas que foram feitas nos filmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "880cf9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negativa \n",
      "\n",
      "Este é sem dúvida o pior filme que eu já vi. E acredite em mim, eu vi muitos filmes. A reviravolta inacreditável que o filme faz - passando de um extremamente mau filme \"Formas de vida alienígenas habitam a terra\", com um filme que tenta espalhar um arquicristiano \"O dia do julgamento está próximo, buscar Jesus ou queimar por toda a eternidade em as dívidas ardentes do inferno \"mensagem - deixou-me atordoado depois de ter sido atormentado por 85 minutos. Até mesmo os cristãos religiosos devem se envergonhar ou ficar furiosos ao ver suas crenças postadas dessa maneira. Eu não sabia o que fazer comigo quando assisti a atuação horrível que poderia ter sido realizada por crianças de 7 anos de idade. Simplesmente repugnante. Eu não sou cristão nem muito religioso. Mas se eu estivesse, não teria mais medo do Inferno. Rich Christiano mostrou ser algo muito pior.\n"
     ]
    }
   ],
   "source": [
    "# analisando um exemplo de critica, essa parte é importante para entender se é longo, se tem numeros no texto, se tem espaços etc..\n",
    "print(\"Negativa \\n\")\n",
    "print(resenha.text_pt[189])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c3f3d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg    24765\n",
      "pos    24694\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# também é importante analisar a proporção de dados que eu tenho para o ML, isso porque se os dados estiverem com proporções diferentes eles ficam desbalanceados\n",
    "# sendo necessario um tratamento de balanceamento, nesse caso os dados estão proximos.\n",
    "\n",
    "print(resenha.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "603668e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49454</th>\n",
       "      <td>49456</td>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>Como a média de votos era muito baixa, e o fat...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49455</th>\n",
       "      <td>49457</td>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>O enredo teve algumas reviravoltas infelizes e...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49456</th>\n",
       "      <td>49458</td>\n",
       "      <td>I am amazed at how this movieand most others h...</td>\n",
       "      <td>Estou espantado com a forma como este filme e ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49457</th>\n",
       "      <td>49459</td>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>A Christmas Together realmente veio antes do m...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49458</th>\n",
       "      <td>49460</td>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>O drama romântico da classe trabalhadora do di...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49459 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            text_en  \\\n",
       "0          1  Once again Mr. Costner has dragged out a movie...   \n",
       "1          2  This is an example of why the majority of acti...   \n",
       "2          3  First of all I hate those moronic rappers, who...   \n",
       "3          4  Not even the Beatles could write songs everyon...   \n",
       "4          5  Brass pictures movies is not a fitting word fo...   \n",
       "...      ...                                                ...   \n",
       "49454  49456  Seeing as the vote average was pretty low, and...   \n",
       "49455  49457  The plot had some wretched, unbelievable twist...   \n",
       "49456  49458  I am amazed at how this movieand most others h...   \n",
       "49457  49459  A Christmas Together actually came before my t...   \n",
       "49458  49460  Working-class romantic drama from director Mar...   \n",
       "\n",
       "                                                 text_pt sentiment  \\\n",
       "0      Mais uma vez, o Sr. Costner arrumou um filme p...       neg   \n",
       "1      Este é um exemplo do motivo pelo qual a maiori...       neg   \n",
       "2      Primeiro de tudo eu odeio esses raps imbecis, ...       neg   \n",
       "3      Nem mesmo os Beatles puderam escrever músicas ...       neg   \n",
       "4      Filmes de fotos de latão não é uma palavra apr...       neg   \n",
       "...                                                  ...       ...   \n",
       "49454  Como a média de votos era muito baixa, e o fat...       pos   \n",
       "49455  O enredo teve algumas reviravoltas infelizes e...       pos   \n",
       "49456  Estou espantado com a forma como este filme e ...       pos   \n",
       "49457  A Christmas Together realmente veio antes do m...       pos   \n",
       "49458  O drama romântico da classe trabalhadora do di...       pos   \n",
       "\n",
       "       classificacao  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "49454              1  \n",
       "49455              1  \n",
       "49456              1  \n",
       "49457              1  \n",
       "49458              1  \n",
       "\n",
       "[49459 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#para classificar esses dados, vou abrir uma nova coluna no meu dataset onde 1 é positivo e 0 é negativo (as criticas), uso o metodo replace do pandas para fazer essa substituicao\n",
    "\n",
    "classificacao = resenha[\"sentiment\"].replace([\"neg\", \"pos\"], [0,1])\n",
    "resenha[\"classificacao\"] = classificacao                                                    \n",
    "resenha                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74555f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48675fdd",
   "metadata": {},
   "source": [
    "## Bag of Words: criando representações da linguagem humana - exemplo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af7c1ec",
   "metadata": {},
   "source": [
    "#### Nesse proxima etapa eu vou construir um modelo de bag of words, que basicamente é um saco de palavras, ou um vocabulario para simplificar\n",
    "#### esse vocabulario elimina a repeticao das palavras, é usada como um recurso para treinar um classificador, cada chave é a palavra e cada valor é o número de ocorrências dessa palavra no documento de texto fornecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aea2015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nessa etapa eu trago um metodo de feature para que seja feita a extraçao do texto e CountVectorizer é a maneira de converte uma coleção de documentos de texto em uma matriz de contagem de tokens\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "#explicando o cod, aqui eu abri uma variavel e coloquei uma frase qualquer para teste, depois disso apliquei o CountVectorizer dentro da minha variavel text \n",
    "\n",
    "texto = [\"Assisti um filme ótimo\", \"Assisti um filme ruim\"]\n",
    "vetorizar = CountVectorizer()\n",
    "bag_of_words= vetorizar.fit_transform(texto)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c200d3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patricia.sousa\\Anaconda4\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['assisti', 'filme', 'ruim', 'um', 'ótimo']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aqui é o resultado da minha Bag of words, o algoritimo faz um voculario sem repeticao das palavras\n",
    "vetorizar.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8d5ddce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assisti</th>\n",
       "      <th>filme</th>\n",
       "      <th>ruim</th>\n",
       "      <th>um</th>\n",
       "      <th>ótimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   assisti  filme  ruim  um  ótimo\n",
       "0        1      1     0   1      1\n",
       "1        1      1     1   1      0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dentro da minha variavel Bag of words os dados não vetorizados como uma matriz esparsa, é uma ma matriz grande, geralmente, e a maioria dos valores é 0, com alguns valores numéricos. Ou seja, é uma matriz cheia de zeros\n",
    "#O DataFrame convencional não interpreta a matriz esparsa então vou usar o metodo SparseDataFrame para construir essa tabela\n",
    "\n",
    "matriz_esparsa = pd. DataFrame.sparse.from_spmatrix(bag_of_words,columns= vetorizar.get_feature_names())\n",
    "matriz_esparsa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c8773",
   "metadata": {},
   "source": [
    "## Bag of Words: criando representações da linguagem humana - Base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d4e3a",
   "metadata": {},
   "source": [
    "#### P.s.: A vetoração dos dados está sendo feita tanto para os dados de teste quanto para os de treino dentro do modelo de ML, dessa maneira eu amenizo o risco de ter dados teste que não contem na minha lista de vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f38d53ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49459, 50)\n"
     ]
    }
   ],
   "source": [
    "#Fiz aplicacao do CountVectorizer na minha base original resenhas, porém deu uma lista de vetor muito grande \n",
    "# Isso computacionalmente é inscalavél, custa tempo de processamento e memoria, uma maneira que  eu vou usar para amenizar esses vetores vai ser \n",
    "#O Max_features do proprio CountVectorizer  com esse metodo, eu escolho a quantidade de vetores que eu quero, e com isso vai amenizar os vetores, mantendo os que mais se repetem dentro do dataframe \n",
    "\n",
    "vetorizar = CountVectorizer(lowercase=False, max_features=50)\n",
    "bag_of_words = vetorizar.fit_transform(resenha.text_pt)\n",
    "print(bag_of_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c40c504b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6583097452486858\n"
     ]
    }
   ],
   "source": [
    "# Aqui eu apliquei o treinamento no algoritimo considerando a base bag_of words e a base resenha, para apurar os resultados \n",
    "#também espelhei acurarica de acertos, que nesse caso é o quanto o algoritimo consegui identificar e classificar as palavras boas e ruims das resenhas \n",
    "#Acurácia: indica uma performance geral do modelo. Dentre todas as classificações, quantas o modelo classificou corretamente nesse caso acerto de 0.65%\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words,resenha.classificacao,random_state = 42)\n",
    "\n",
    "regressao_logistica = LogisticRegression()\n",
    "regressao_logistica.fit(treino, classe_treino)\n",
    "acuracia = regressao_logistica.score(teste, classe_teste)\n",
    "print(acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e641faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6583097452486858\n"
     ]
    }
   ],
   "source": [
    "#Daqui para a frente, objetivo será trazer o mais perto possível as palavras com maior relevância semântica para a casa dos 50, \n",
    "#isto é, que as palavras mais relevantes possíveis estejam perto das 50 primeiras posições. Como vou fazer isso sempre, e sempre vou querer medir, vou transformar isto numa função\n",
    "\n",
    "def classificar_texto(texto, coluna_texto, coluna_classificacao):\n",
    "    vetorizar = CountVectorizer(lowercase=False, max_features=50)\n",
    "    bag_of_words = vetorizar.fit_transform(texto[coluna_texto])\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words,resenha.classificacao,random_state = 42)\n",
    "    \n",
    "    regressao_logistica = LogisticRegression(solver = \"lbfgs\")\n",
    "    regressao_logistica.fit(treino, classe_treino)\n",
    "    return regressao_logistica.score(teste, classe_teste)\n",
    "print(classificar_texto(resenha, \"text_pt\", \"classificacao\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
